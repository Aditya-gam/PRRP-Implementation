{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRRP Experimental Framework\n",
    "\n",
    "This notebook implements PhaseÂ 1 of the PRRP experimental framework. It supports:\n",
    "\n",
    "1. Loading spatial (shapefile) and graph (METIS) datasets.\n",
    "2. Running experiments on spatial regionalization (using PRRP from `src/spatial_prrp.py`) and graph partitioning (using PRRP from `src/graph_prrp.py` and PyMETIS from `src/pymetis_partition.py`).\n",
    "3. Logging and storing performance metrics (execution time, success probability, effectiveness, and completeness).\n",
    "4. Generating performance visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Add root directory to sys.path so that src modules can be imported\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if ROOT_DIR not in sys.path:\n",
    "    sys.path.insert(0, ROOT_DIR)\n",
    "\n",
    "# Set METIS DLL environment variable inside Jupyter Notebook\n",
    "os.environ[\"METIS_DLL\"] = \"/opt/homebrew/Cellar/metis/5.1.0/lib/libmetis.dylib\"\n",
    "\n",
    "# Verify the variable is correctly set\n",
    "print(f\"METIS_DLL is set to: {os.environ.get('METIS_DLL')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the src directory is in the Python path\n",
    "SRC_DIR = os.path.join(ROOT_DIR, \"src\")\n",
    "if SRC_DIR not in sys.path:\n",
    "\tsys.path.insert(0, SRC_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PRRP modules\n",
    "from src.prrp_data_loader import load_shapefile, load_metis_graph\n",
    "from src.spatial_prrp import run_prrp, run_parallel_prrp\n",
    "from src.metis_parser import load_graph_from_metis\n",
    "from src.pymetis_partition import partition_graph_pymetis\n",
    "from src.graph_prrp import run_graph_prrp\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging to display info messages\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', filename=\"output.txt\", filemode=\"w\")\n",
    "logging.basicConfig(\n",
    "    filename=\"output.txt\",  # Log output to a file\n",
    "    filemode=\"w\",           # Overwrite the file each run\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    level=logging.INFO      # Adjust log level as needed\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Configuration\n",
    "\n",
    "In this section we define:\n",
    "\n",
    "- **Dataset paths:** For the spatial and graph datasets.\n",
    "- **Parameter settings:** Such as the number of regions, sample size (M), maximum retries (MR), and number of cores (Q).\n",
    "- **Output directories:** For saving results and figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
    "\n",
    "SPATIAL_DATASET_NAME = \"Tracts\"  # Just a label\n",
    "SPATIAL_DATASET_PATH = os.path.join(DATA_DIR, \"cb_2015_42_tract_500k\", \"cb_2015_42_tract_500k.shp\")\n",
    "\n",
    "GRAPH_DATASET_NAME = \"PGPgiantcompo\"  # Just a label\n",
    "GRAPH_DATASET_PATH = os.path.join(DATA_DIR, \"PGPgiantcompo.graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters for spatial PRRP\n",
    "P_PERCENTAGES = [0.01, 0.02, 0.03]  # p as fraction of dataset size\n",
    "SPATIAL_SAMPLE_SIZES = [10, 50, 100]  # M\n",
    "SPATIAL_MR_VALUES = [10, 30, 50]\n",
    "SPATIAL_Q_VALUES = [1, 2, 4]\n",
    "\n",
    "# 4) Parameter grids for graph experiments\n",
    "GRAPH_P_VALUES = [5, 10, 20]   # number of partitions\n",
    "GRAPH_MR_VALUES = [5, 20, 50]  # max retries\n",
    "GRAPH_MS_VALUES = [5, 10]      # max partition size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directories for results and figures\n",
    "RESULTS_DIR = os.path.join(ROOT_DIR, \"results/final_results\")\n",
    "FIGURES_DIR = os.path.join(ROOT_DIR, \"results/figures\")\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(FIGURES_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions for Experimentation\n",
    "\n",
    "The following helper functions are used to:\n",
    "\n",
    "- Load datasets (spatial or graph).\n",
    "- Compute random target cardinalities for spatial regions.\n",
    "- Run a spatial experiment (using PRRP).\n",
    "- Run a graph partitioning experiment (using both PRRP and PyMETIS for comparison).\n",
    "- Save the results in CSV/JSON format.\n",
    "- Generate visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_solution(solution, cardinalities):\n",
    "    \"\"\"\n",
    "    Checks if a solution is valid, i.e., has exactly one region\n",
    "    per cardinality in 'cardinalities'.\n",
    "    \"\"\"\n",
    "    region_sizes = sorted([len(r) for r in solution])\n",
    "    sorted_cardinalities = sorted(cardinalities)\n",
    "    return (region_sizes == sorted_cardinalities)\n",
    "\n",
    "def count_valid_regions(solution, cardinalities):\n",
    "    \"\"\"\n",
    "    Counts how many regions match any of the cardinalities.\n",
    "    This helps measure partial completeness.\n",
    "    \"\"\"\n",
    "    c_copy = list(cardinalities)\n",
    "    valid_count = 0\n",
    "    for region in solution:\n",
    "        size_r = len(region)\n",
    "        if size_r in c_copy:\n",
    "            valid_count += 1\n",
    "            c_copy.remove(size_r)\n",
    "    return valid_count\n",
    "\n",
    "def compute_spatial_metrics(solutions, cardinalities):\n",
    "    \"\"\"\n",
    "    Returns {success_probability, completeness, effectiveness, num_solutions}.\n",
    "    For demonstration, we set effectiveness = success_probability\n",
    "    since we don't track iteration attempts here.\n",
    "    \"\"\"\n",
    "    p = len(cardinalities)\n",
    "    total_solutions = len(solutions)\n",
    "    if total_solutions == 0:\n",
    "        return {\n",
    "            \"success_probability\": 0.0,\n",
    "            \"completeness\": 0.0,\n",
    "            \"effectiveness\": 0.0,\n",
    "            \"num_solutions\": 0\n",
    "        }\n",
    "    fully_valid = 0\n",
    "    sum_valid_regions = 0\n",
    "    for sol in solutions:\n",
    "        if is_valid_solution(sol, cardinalities):\n",
    "            fully_valid += 1\n",
    "        sum_valid_regions += count_valid_regions(sol, cardinalities)\n",
    "\n",
    "    # Computing success probability\n",
    "    success_probability = fully_valid / total_solutions\n",
    "    \n",
    "    # Computing completeness\n",
    "    completeness = 0.0\n",
    "    for sol in solutions:\n",
    "        completeness += count_valid_regions(sol, cardinalities) / float(p)\n",
    "    completeness = completeness / total_solutions\n",
    "\n",
    "    # Computing effectiveness\n",
    "    total_iterations = 1*total_solutions  # Assume 1 iteration per solution\n",
    "    effectiveness = fully_valid / total_iterations\n",
    "\n",
    "    return {\n",
    "        \"success_probability\": success_probability,\n",
    "        \"completeness\": completeness,\n",
    "        \"effectiveness\": effectiveness,\n",
    "        \"num_solutions\": total_solutions\n",
    "    }\n",
    "\n",
    "def generate_cardinalities(total_areas, num_regions):\n",
    "    \"\"\"\n",
    "    Simple random cardinalities that sum to total_areas.\n",
    "    \"\"\"\n",
    "    cardinalities = [1]*num_regions\n",
    "    remainder = total_areas - num_regions\n",
    "    for i in range(num_regions - 1):\n",
    "        if remainder <= 0:\n",
    "            break\n",
    "        add = random.randint(0, remainder)\n",
    "        cardinalities[i] += add\n",
    "        remainder -= add\n",
    "    \n",
    "    # Add any remaining areas to the last region\n",
    "    cardinalities[-1] += remainder\n",
    "    \n",
    "    # Shuffle the cardinalities for randomness\n",
    "    random.shuffle(cardinalities)\n",
    "    return cardinalities\n",
    "\n",
    "def run_single_spatial_experiment(dataset_name, shapefile_path, p_percentage, M, MR, Q):\n",
    "    \"\"\"\n",
    "    Runs a single experiment for the shapefile with the given parameters.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Loading shapefile: {shapefile_path}\")\n",
    "    from src.prrp_data_loader import load_shapefile\n",
    "    areas = load_shapefile(shapefile_path)\n",
    "    if areas is None or len(areas) == 0:\n",
    "        logger.error(f\"Failed to load or empty shapefile {shapefile_path}.\")\n",
    "        return None\n",
    "\n",
    "    total_areas = len(areas)\n",
    "    num_regions = max(1, int(total_areas * p_percentage))\n",
    "    cardinalities = generate_cardinalities(total_areas, num_regions)\n",
    "\n",
    "    logger.info(f\"Dataset={dataset_name}, total_areas={total_areas}, \"\n",
    "                f\"p={p_percentage} -> num_regions={num_regions}, M={M}, MR={MR}, Q={Q}\")\n",
    "    logger.info(f\"Cardinalities: {cardinalities}\")\n",
    "\n",
    "    start_t = time.time()\n",
    "    solutions = run_parallel_prrp(\n",
    "        areas=areas,\n",
    "        num_regions=num_regions,\n",
    "        cardinalities=cardinalities,\n",
    "        solutions_count=M,\n",
    "        num_threads=Q,\n",
    "        use_multiprocessing=(Q>1)\n",
    "    )\n",
    "    end_t = time.time()\n",
    "    exec_time = end_t - start_t\n",
    "\n",
    "    # Compute metrics\n",
    "    metrics = compute_spatial_metrics(solutions, cardinalities)\n",
    "\n",
    "    result = {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"total_areas\": total_areas,\n",
    "        \"p_percentage\": p_percentage,\n",
    "        \"num_regions\": num_regions,\n",
    "        \"sample_size\": M,\n",
    "        \"MR\": MR,\n",
    "        \"Q\": Q,\n",
    "        \"execution_time_sec\": exec_time,\n",
    "        \"success_probability\": metrics[\"success_probability\"],\n",
    "        \"completeness\": metrics[\"completeness\"],\n",
    "        \"effectiveness\": metrics[\"effectiveness\"],\n",
    "        \"num_solutions_generated\": metrics[\"num_solutions\"],\n",
    "        \"solutions\": solutions,\n",
    "    }\n",
    "    return result\n",
    "\n",
    "def run_spatial_experiments_all():\n",
    "    \"\"\"\n",
    "    Sweeps over the parameter grids for the single shapefile,\n",
    "    returns a DataFrame of results, and saves CSV/JSON.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    dataset_name = SPATIAL_DATASET_NAME\n",
    "    shapefile_path = SPATIAL_DATASET_PATH\n",
    "\n",
    "    if not os.path.isfile(shapefile_path):\n",
    "        logger.error(f\"Shapefile not found: {shapefile_path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    for pperc in P_PERCENTAGES:\n",
    "        for M in SPATIAL_SAMPLE_SIZES:\n",
    "            for MR in SPATIAL_MR_VALUES:\n",
    "                for Q in SPATIAL_Q_VALUES:\n",
    "                    logger.info(f\"Running spatial experiment: p={pperc}, M={M}, MR={MR}, Q={Q}\")\n",
    "                    res = run_single_spatial_experiment(dataset_name, shapefile_path, pperc, M, MR, Q)\n",
    "                    if res:\n",
    "                        records.append(res)\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    df_csv = os.path.join(RESULTS_DIR, \"spatial_experiments.csv\")\n",
    "    df_json = os.path.join(RESULTS_DIR, \"spatial_experiments.json\")\n",
    "    df.to_csv(df_csv, index=False)\n",
    "    df.to_json(df_json, orient=\"records\", indent=2)\n",
    "    logger.info(f\"Saved spatial experiment results to {df_csv} and {df_json}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Experiments and Collecting Metrics\n",
    "\n",
    "The following cells run the spatial and graph experiments over a range of parameter settings.\n",
    "For demonstration, we run a single configuration for each type. In practice, you might loop over\n",
    "multiple parameter combinations and aggregate the results into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_graph_experiment(dataset_name, graph_file_path, p, MR, MS):\n",
    "    \"\"\"\n",
    "    Runs a single experiment for the graph dataset with given parameters,\n",
    "    comparing graph-based PRRP vs. PyMETIS.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Loading METIS graph from: {graph_file_path}\")\n",
    "    adj_list, num_nodes, num_edges = load_graph_from_metis(graph_file_path)\n",
    "    if not adj_list or num_nodes==0:\n",
    "        logger.error(f\"Failed to load or empty graph {graph_file_path}.\")\n",
    "        return None\n",
    "\n",
    "    # Run graph-based PRRP\n",
    "    start_t = time.time()\n",
    "    prrp_partitions = run_graph_prrp(adj_list, p, 0, MR, MS)\n",
    "    prrp_time = time.time() - start_t\n",
    "\n",
    "    # Run PyMETIS\n",
    "    start_t = time.time()\n",
    "    pymetis_parts = partition_graph_pymetis(adj_list, p)\n",
    "    pymetis_time = time.time() - start_t\n",
    "\n",
    "    result = {\n",
    "        \"graph_dataset\": dataset_name,\n",
    "        \"num_nodes\": num_nodes,\n",
    "        \"num_edges\": num_edges,\n",
    "        \"p\": p,\n",
    "        \"MR\": MR,\n",
    "        \"MS\": MS,\n",
    "        \"prrp_time_sec\": prrp_time,\n",
    "        \"pymetis_time_sec\": pymetis_time,\n",
    "        \"pymetis_parts\" : pymetis_parts,\n",
    "        \"prrp_parts\": prrp_partitions\n",
    "    }\n",
    "    return result\n",
    "\n",
    "def run_graph_experiments_all():\n",
    "    \"\"\"\n",
    "    Sweeps over the parameter grids for the single graph,\n",
    "    returns a DataFrame of results, and saves CSV.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    dataset_name = GRAPH_DATASET_NAME\n",
    "    graph_file_path = GRAPH_DATASET_PATH\n",
    "\n",
    "    if not os.path.isfile(graph_file_path):\n",
    "        logger.error(f\"Graph file not found: {graph_file_path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    for pval in GRAPH_P_VALUES:\n",
    "        for MR in GRAPH_MR_VALUES:\n",
    "            for MS in GRAPH_MS_VALUES:\n",
    "                logger.info(f\"Running graph experiment: p={pval}, MR={MR}, MS={MS}\")\n",
    "                res = run_single_graph_experiment(dataset_name, graph_file_path, pval, MR, MS)\n",
    "                if res:\n",
    "                    records.append(res)\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    df_csv = os.path.join(RESULTS_DIR, \"graph_experiments.csv\")\n",
    "    df.to_csv(df_csv, index=False)\n",
    "    df_json = os.path.join(RESULTS_DIR, \"graph_experiments.json\")\n",
    "    df.to_json(df_json, orient=\"records\", indent=2)\n",
    "    logger.info(f\"Saved graph experiment results to {df_csv} and {df_json}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Visualizations\n",
    "\n",
    "Here we generate a simple visualization of the execution time from the spatial experiment.\n",
    "In a full evaluation, you would plot multiple performance metrics across parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_vs_parameter(df, xparam, metric, title, logy=False, save_path=None):\n",
    "    \"\"\"\n",
    "    Plots a single line: metric vs. xparam from the DataFrame.\n",
    "    \"\"\"\n",
    "    df_sorted = df.sort_values(xparam)\n",
    "    x = df_sorted[xparam]\n",
    "    y = df_sorted[metric]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(x, y, marker='o', linestyle='-')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xparam)\n",
    "    plt.ylabel(metric)\n",
    "    if logy:\n",
    "        plt.yscale(\"log\")\n",
    "    plt.grid(True)\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        logger.info(f\"Saved figure to {save_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the regions in shapefile\n",
    "def visualize_shapefile(shapefile_path, regions):\n",
    "    \"\"\"\n",
    "    Visualizes the shapefile with regions highlighted.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Visualizing shapefile: {shapefile_path}\")\n",
    "    gdf = gpd.read_file(shapefile_path)\n",
    "    gdf[\"region\"] = -1  # Default region\n",
    "    for i, region in enumerate(regions):\n",
    "        gdf.loc[gdf[\"GEOID\"].isin(region), \"region\"] = i\n",
    "    gdf.plot(column=\"region\", cmap=\"tab20\", figsize=(10, 10))\n",
    "    plt.title(\"Regions in Shapefile\")\n",
    "    plt.show()\n",
    "\n",
    "# Example: visualize the first solution from the spatial experiments\n",
    "if not df_spatial.empty:\n",
    "    visualize_shapefile(SPATIAL_DATASET_PATH, df_spatial.iloc[0][\"solutions\"][0])\n",
    "\n",
    "# Visualizing the graph partitions\n",
    "def visualize_graph_partitions(graph_file_path, partitions):\n",
    "    \"\"\"\n",
    "    Visualizes the graph partitions.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Visualizing graph partitions: {graph_file_path}\")\n",
    "    G = load_metis_graph(graph_file_path)\n",
    "    pos = nx.spring_layout(G)\n",
    "    colors = np.linspace(0, 1, len(partitions))\n",
    "    for i, partition in enumerate(partitions):\n",
    "        nx.draw_networkx_nodes(G, pos, nodelist=partition, node_size=50, node_color=[colors[i]]*len(partition))\n",
    "    nx.draw_networkx_edges(G, pos, alpha=0.5)\n",
    "    plt.title(\"Graph Partitions\")\n",
    "    plt.show()\n",
    "\n",
    "# Example: visualize the first solution from the graph experiments\n",
    "if not df_graph.empty:\n",
    "    visualize_graph_partitions(GRAPH_DATASET_PATH, df_graph.iloc[0][\"prrp_parts\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Suite Execution \n",
    "\n",
    "Finally we setup and run the experimentation for our spatial and graph datasets and plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"=== Starting Spatial Experiments ===\")\n",
    "    df_spatial = run_spatial_experiments_all()\n",
    "    logger.info(\"=== Spatial Experiments Completed ===\")\n",
    "\n",
    "    # Example: let's pick a single slice of df_spatial to plot execution time vs. M\n",
    "    # Suppose we fix p_percentage=0.01, MR=10, Q=1\n",
    "    subdf = df_spatial[\n",
    "        (df_spatial[\"p_percentage\"] == 0.01) &\n",
    "        (df_spatial[\"MR\"] == 10) &\n",
    "        (df_spatial[\"Q\"] == 1)\n",
    "    ]\n",
    "    # We can plot \"execution_time_sec\" vs. \"sample_size\"\n",
    "    if not subdf.empty:\n",
    "        plot_metric_vs_parameter(\n",
    "            subdf,\n",
    "            xparam=\"sample_size\",\n",
    "            metric=\"execution_time_sec\",\n",
    "            title=\"Execution Time vs. Sample Size (p=1%, MR=10, Q=1)\",\n",
    "            logy=True,\n",
    "            save_path=os.path.join(FIGURES_DIR, \"figure_spatial_time_vs_M.png\")\n",
    "        )\n",
    "\n",
    "    logger.info(\"=== Starting Graph Experiments ===\")\n",
    "    df_graph = run_graph_experiments_all()\n",
    "    logger.info(\"=== Graph Experiments Completed ===\")\n",
    "\n",
    "    # Example: plot PRRP time vs. p\n",
    "    # Suppose we fix MR=5, MS=5\n",
    "    subdf_g = df_graph[(df_graph[\"MR\"] == 5) & (df_graph[\"MS\"] == 5)]\n",
    "    if not subdf_g.empty:\n",
    "        plot_metric_vs_parameter(\n",
    "            subdf_g,\n",
    "            xparam=\"p\",\n",
    "            metric=\"prrp_time_sec\",\n",
    "            title=\"Graph PRRP Time vs. p (MR=5, MS=5)\",\n",
    "            logy=True,\n",
    "            save_path=os.path.join(FIGURES_DIR, \"figure_graph_time_vs_p.png\")\n",
    "        )\n",
    "\n",
    "    logger.info(\"All experiments completed. Results and figures are saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
